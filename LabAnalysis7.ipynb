{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Dn-p9FDnyOrA"
      ],
      "authorship_tag": "ABX9TyP4UY7TWR+rakDzUbugJZ6/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NYU-IEP-2022-2023-Assignments/LabAnalysis7/blob/main/LabAnalysis7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vycMKg1Wmly"
      },
      "source": [
        "#Goal of this analysis\n",
        "The predicted rotation due to driving the pendulum is given by\n",
        "\n",
        "$\\Delta \\theta = -\\frac{2 b \\Delta a}{a^2 - b^2} \\approx -\\frac{ab}{a^2-b^2}\\frac{\\Delta U}{U}f(\\phi) \\approx -\\frac{b}{a}\\frac{\\Delta U}{U}f(\\phi) $, with \n",
        "\n",
        "$f(\\phi) = \\cot(2\\phi)$ (my formula)\n",
        "\n",
        "or\n",
        "\n",
        "$f(\\phi) = \\frac{{\\pi}/{2} - \\phi}{2 \\tan(\\phi)}$ (Schumacher and Tarbet eq 19)\n",
        "\n",
        "or\n",
        "\n",
        "$f(\\phi) = \\frac{{\\pi}/{2} - \\phi}{2 \\sin(\\phi)}$ (Schumacher and Tarbet eq 19)\n",
        "\n",
        "\n",
        "For a given interval of time, call $\\Delta \\theta_{meas} = (\\theta_{final} - \\theta_{initial}) - \\int \\Omega_{pred}(t)dt$, where $\\Omega_{pred} = \\frac{3}{8}\\omega \\frac{ab}{L^2} - 9.8^\\circ/hr$ is the predicted rotation due to the elliptical orbit and the rotation of the earth.\n",
        "\n",
        "Then both models predict a graph of $\\Delta \\theta_{meas}$ vs. $ \\frac{2 b \\Delta a}{a^2 - b^2}$ will show a linear relation with an intercept of 0 and different slopes, depending on the phase. Crucially, my model predicts that the slope will be positive for $\\phi < 45^\\circ$ and negative for $\\phi > 45^\\circ$, which Schumacher and Tarbet predict the slope will always be positive. \n",
        "\n",
        "So our goal is, first, for every pulse.\n",
        "\n",
        "1. Calculate $\\Delta \\theta_{meas} = \\theta_{final} - \\theta_{initial} - \\int \\Omega_{pred}(t)dt$\n",
        "2. Calculate a \"rotation factor:\" $\\frac{2 b da}{a^2-b^2}$ for the same interval\n",
        "\n",
        "Then use this information and sort each pulse by the phase. \n",
        "1. For each phase, make a plot of $\\Delta \\theta_{meas}$ vs. $R$, the \"rotation factor\" - does the sign of the slope vs. phase match either model's predictions?\n",
        "1. For each phase calculate the best fit to  $\\Delta \\theta_{meas} = m(\\phi) R$\n",
        "1. Plot $m(\\phi)$ vs. $\\phi$ and compare to model predictions\n",
        "\n",
        "First, though we'll need to verify that we're correctly modeling $\\Omega_{pred}$ and we'll need to figure out how much bigger $\\Delta A$ is than we measured it to be because of damping. \n",
        "\n",
        "Let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpswBbfWcR0E"
      },
      "source": [
        "#Initial library includes and installations\n",
        "run once - does not require you to edit anything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHTWtceOIVdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f065d349-f5e6-421f-d233-93121fbf985d"
      },
      "source": [
        "!pip install munch\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, glob\n",
        "from munch import munchify\n",
        "from munch import Munch\n",
        "import scipy.stats\n",
        "from sklearn import linear_model, datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch) (1.16.0)\n",
            "Installing collected packages: munch\n",
            "Successfully installed munch-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxRStqhL2g5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGierwNjcdQa"
      },
      "source": [
        "#Function definitions and constants\n",
        "Run once - does not require you to edit anything\n",
        "\n",
        "These functions are provided for you - see function definitions and comments for more information on their return values and usage\n",
        "\n",
        "  1. `loadDataSet(filename)` - loads an individual .json file and checks it for really large jumps in major axis angle, which would indicate a problem with the fits\n",
        "  1. `loadAllDataSets(startdir)` - loads all json files in a directory\n",
        "  1. `(m,m_e) = fitLineThroughZero(x,y)`: like fitLine, but with b fixed to 0\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3wquqyKbOpM"
      },
      "source": [
        "gaccel = 9802\n",
        "\n",
        "nyc_latitude =40.730610\n",
        "deghr = np.rad2deg(3600)\n",
        "omega_foucault = -15*np.sin(np.deg2rad(nyc_latitude))/deghr\n",
        "\n",
        "\n",
        "MAJAXIS = 0\n",
        "MINAXIS = 1\n",
        "THETA = 2\n",
        "BOBROT = 3\n",
        "DPHI = 4\n",
        "\n",
        "\n",
        "def loadDataSet(filename):\n",
        "  file = open(filename,'r')\n",
        "  results = json.load(file)\n",
        "  file.close\n",
        "  dataset = munchify(results) #can be accessed as a structure or a dict\n",
        "  dataset.filename = filename\n",
        "  valid = []\n",
        "  \n",
        "  for f in dataset.fits:\n",
        "    f2 = f.copy()\n",
        "    f2.pop('orbitPath',None)\n",
        "    f2.pop('magPath',None)\n",
        "    f2.pop('pulsePath',None)\n",
        "    for k in f2.keys():\n",
        "      f[k] = np.array(f[k])\n",
        "\n",
        "    f.setupNumber = dataset.setupNumber\n",
        "    f.section = dataset.section\n",
        "\n",
        "    f.theta = np.unwrap(f.theta)\n",
        "    f.getSmoothTheta = scipy.interpolate.UnivariateSpline(f.t, f.theta)\n",
        "    f.getSmoothA = scipy.interpolate.UnivariateSpline(f.t, f.majaxis)\n",
        "    f.getSmoothB = scipy.interpolate.UnivariateSpline(f.t, f.minaxis)\n",
        "    f.getPhase = scipy.interpolate.UnivariateSpline(f.t, np.arange(0,len(f.t))*np.pi*2 + f.phaseOffset)\n",
        "    dp = np.diff(f.theta)\n",
        "    valid.append((np.abs(dp) < np.pi/4).all() and (np.abs(f.majaxis) < 500).all() and (np.abs(f.minaxis) < 500).all() and (np.abs(f.t-f.t[0]) < 3600).all()) #extremely large jump from one swing to the next - bad fit; major or minor axis exceeding 50 cm - bad fit\n",
        "    f.pulse = Munch()\n",
        "    try:\n",
        "      pulseValid = np.logical_and(np.logical_and(f.pulseTime > f.t[0], f.pulseTime < f.t[-1]), np.logical_and(f.pulseEnergy > 0, f.pulseEnergy < 10000))\n",
        "      dU = scipy.ndimage.median_filter(f.pulseEnergy[pulseValid], size = (5,))\n",
        "\n",
        "      ptime = f.pulseTime[pulseValid]\n",
        "      pind = np.round((ptime-ptime[0])*2/f.period)\n",
        "\n",
        "      if (pind[-1] > len(pind) - 1):\n",
        "        print('{}: filling in {} missing pulses'.format(dataset.filename, pind[-1]-len(pind)+1))\n",
        "        f.pulse.time = np.interp(np.arange(pind[-1] + 1), pind, ptime)\n",
        "        f.pulse.dU = np.interp(np.arange(pind[-1] + 1), pind, dU)\n",
        "      else:\n",
        "        f.pulse.time = ptime\n",
        "        f.pulse.dU = dU\n",
        "      f.pulse.phase = np.mod(f.getPhase(f.pulse.time), np.pi)\n",
        "      f.pulse.a = f.getSmoothA(f.pulse.time)\n",
        "      f.pulse.b = f.getSmoothB(f.pulse.time)\n",
        "      f.pulse.theta = f.getSmoothTheta(f.pulse.time)\n",
        "      try:\n",
        "        f.pulse.counter = np.unwrap(f.pulse, period=256)\n",
        "      except:\n",
        "        f.pulse.counter = np.arange(pind[-1] + 1)\n",
        "        #print('{}: this data was processed with an older version of the mag fitter'.format(dataset.filename))\n",
        "    except:\n",
        "      f.pulse.time = np.zeros((0,))\n",
        "      f.pulse.dU = np.zeros((0,))\n",
        "      f.pulse.phase = np.zeros((0,))\n",
        "      f.pulse.a = np.zeros((0,))\n",
        "      f.pulse.b = np.zeros((0,))\n",
        "      f.pulse.theta = np.zeros((0,))\n",
        "      f.pulse.counter = np.zeros((0,))\n",
        "    \n",
        "    f.nopulse = Munch()\n",
        "    try:\n",
        "      if (len(f.pulse.time) > 0):\n",
        "        tmin = np.min(f.pulse.time)\n",
        "        tmax = np.max(f.pulse.time)\n",
        "        if (any(f.t < tmin)):\n",
        "          f.nopulse.time = f.t[f.t < tmin]\n",
        "          try:\n",
        "            f.postpulse = Munch()\n",
        "            f.postpulse.time = f.t[f.t > tmax]\n",
        "            f.postpulse.a = f.getSmoothA(f.postpulse.time)\n",
        "            f.postpulse.b = f.getSmoothB(f.postpulse.time)\n",
        "            f.postpulse.theta = f.getSmoothTheta(f.postpulse.time)\n",
        "          except:\n",
        "            pass\n",
        "        else:\n",
        "          f.nopulse.time = f.t[f.t > tmax]\n",
        "      else:\n",
        "        f.nopulse.time = f.t\n",
        "      f.nopulse.a = f.getSmoothA(f.nopulse.time)\n",
        "      f.nopulse.b = f.getSmoothB(f.nopulse.time)\n",
        "      f.nopulse.theta = f.getSmoothTheta(f.nopulse.time)\n",
        "    except:\n",
        "      f.nopulse.time = np.zeros((0,))\n",
        "      f.nopulse.a = np.zeros((0,))\n",
        "      f.nopulse.b = np.zeros((0,))\n",
        "      f.nopulse.theta = np.zeros((0,))\n",
        "      \n",
        "  bad = np.array(valid) == False\n",
        "  if (bad.any()):\n",
        "    print('{}: bad fits found in experiments {}'.format(filename, np.where(bad)[0]))\n",
        "    dataset.fits = [dataset.fits[i] for i in np.where(valid)[0]]  \n",
        "  return dataset\n",
        "\n",
        "def loadAllDataSets(startdir):\n",
        "  files = sorted(glob.glob(startdir + '/*.json'))\n",
        "  data = []\n",
        "  for f in files:\n",
        "    d = loadDataSet(f)\n",
        "    if len(d.fits) > 0:\n",
        "      data.append(d)\n",
        "  return data\n",
        "#  return [loadDataSet(f) for f in files]\n",
        "\n",
        "#(m,m_e) = fitLineThroughZero(x,y)\n",
        "#y = m(m +/- m_e)x\n",
        "def fitLineThroughZero(x,y):\n",
        "  m = np.sum(x*y)/np.sum(x**2)\n",
        "  res = y - m*x\n",
        "  m_e = np.sqrt(np.var(res)/np.sum((x-np.mean(x))**2))\n",
        "  return (m,m_e)\n",
        "\n",
        "\n",
        "# value, section, setup = applyFunctionToSet(fun, dataset)\n",
        "# for just value\n",
        "# value = applyFunctionToSet(fun, dataset)[0]\n",
        "# or\n",
        "# value,*_ = applyFunctionToSet(fun, dataset) \n",
        "def applyFunctionToSet(fun, dataset, silenceWarnings = False):\n",
        "  if isinstance(dataset, list):\n",
        "    #https://stackoverflow.com/questions/42376201/how-can-i-get-multiple-lists-as-separate-results-from-a-list-comprehension\n",
        "    v,setup, section =  zip(*[applyFunctionToSet(fun, d, silenceWarnings) for d in dataset])\n",
        "    return np.concatenate(np.atleast_1d(v)), np.concatenate(np.atleast_1d(setup)), np.concatenate(np.atleast_1d(section))\n",
        "  v = []\n",
        "  setup = []\n",
        "  section = []\n",
        "  for f in dataset.fits:\n",
        "    try:\n",
        "      vv = np.atleast_1d(fun(f))\n",
        "      if (vv.size > 0):\n",
        "        section.append(np.ones_like(vv)*dataset.section)\n",
        "        setup.append(np.ones_like(vv)*dataset.setupNumber)\n",
        "        v.append(vv)\n",
        "    except Exception as e:\n",
        "      if (not(silenceWarnings)):\n",
        "        print(\"{}: error {}\".format(f.orbitPath,str(e)))\n",
        "  return np.concatenate(np.atleast_1d(v)), np.concatenate(np.atleast_1d(setup)), np.concatenate(np.atleast_1d(section))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRZ82mnQeKBL"
      },
      "source": [
        "#Fetch and load the data to be analyzed\n",
        "run once\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCynEIfRabj6"
      },
      "source": [
        "!rm -rf data/\n",
        "!git clone https://github.com/NYU-IEP-2022-3-Classroom/lab7-shared-data-everyone data\n",
        "pulsedata = loadAllDataSets('/content/data/')\n",
        "!rm -rf calibrationdata/\n",
        "!git clone https://github.com/NYU-IEP-2022-3-Classroom/lab7-nopulse-shared-data-everyone calibrationdata\n",
        "#for the calibration data, this more complicated structure is needed to fix issues created if non-calibration (i.e. all pulses) data is uploaded to the calibration directory\n",
        "cd =  loadAllDataSets('/content/calibrationdata/')\n",
        "calibrationdata = []\n",
        "for d in cd:\n",
        "  ff = d.fits\n",
        "  d.fits = []\n",
        "  for f in ff:\n",
        "    if (f.nopulse.time.size > 30):\n",
        "      d.fits.append(f)\n",
        "  if(len(d.fits) > 0):\n",
        "    calibrationdata.append(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explanation of the data structure\n",
        "\n",
        "##handy constants\n",
        "\n",
        "I defined some handy constants for you to use\n",
        "```\n",
        "gaccel = 9802 #acceleration due to gravity in mm^2/s\n",
        "\n",
        "nyc_latitude =40.730610 #the place where you are, right now\n",
        "deghr = np.rad2deg(3600) #multiply by deghr to convert rad/s to deg/hr\n",
        "omega_foucault = -15*np.sin(np.deg2rad(nyc_latitude))/deghr #foucault precession rate in radians per second\n",
        "```\n",
        "\n",
        "`pulsedata` contains everyone's data for the driven experimentss - each element of this list is one dataset\n",
        "\n",
        "`calibrationdata` contains everyone's data for the anharmonic precession only calibration\n",
        "\n",
        "\n",
        "\n",
        "## fields in dataset structure\n",
        "- `setupNumber`: number on the wall\n",
        "- `section`: 1-4 which section data came from\n",
        "- `thetaWall`: angle of a line parallel to the wall\n",
        "- `filename`: name of the json file\n",
        "- `fits`: list of fits to individual trials\n",
        "- The `fits` structure contains a lot of data, but the most relevant to you are stored in two substructures\n",
        "  - `fits.pulse`\n",
        "  - `fits.nopulse`\n",
        "  - `fits.pulse` and `fits.nopulse` both contain the following fields\n",
        "    - `time` a reference time, for `fits.pulse` it is the time of each pulse, for `fits.nopulse` \n",
        "    - `a` smoothed estimate of the major axis at each reference time\n",
        "    - `b` a smoothed estimate of the minor axis at each reference time\n",
        "    - `theta` a smoothed estimate of the angle of the major axis at each referene time\n",
        "  - `fits.pulse` contains additional fields\n",
        "    - `phase` the phase of the pulse in radians, mod $\\pi$. In other words, if the pulse fired at 30 degrees = $\\pi/6$ radians, the phase would be 30. \n",
        "    \n",
        "        If the pulse fired at 210 degrees (on the reverse swing) = $7\\pi/6$, the phase would still be $\\pi/6$. This is because the two phases are physically identical (the difference of forward vs backward swing is just an arbitrary choice made at the start of the recording). \n",
        "    - `dU` the measured change in energy. I think there is something wrong with this value as it was recorded to disk, so we won't use it. But it's in there! \n",
        "    - `counter` the number of the pulse, which depending on which version of the mag fitter you ran may start at 0 or a random number between 0 and 255. Each pulse increments 1. You won't use this. But it's in there!\n",
        "  - There are also some additional data stored in `fits` that you'll need (Yes, 'are.' 'Data' is the plural of '[datum](https://https://web.mit.edu/course/21/21.guide/data.htm#:~:text=Datum%20is%20singular%2C%20meaning%20%22one,used%20as%20a%20singular%20noun.)'. 'Larva' is not the plural of '[larvum](https://https://grantome.com/grant/NIH/DP1-OD004064-04).' Instead 'larvae' is the plural of 'larva.'  [Here you go!](https://http://www.biomedicaleditor.com/spelling-tip-latin.html) Also, agenda is plural and agendas is technically nonsense. You should ask \"What's on the agendum for class today?\"\n",
        "    - `fits.period` - the period of the pendulum. \n",
        "    - `fits.L` - contains the estimated length of the pendulum **(in mm**), based on the period. This assumes the experiment was done in NYC and for our purposes is  accurate enough for anywhere on Earth. If you did the experiment on another planet, get in touch with me, and I will show you where to edit the code.\n",
        "    \n",
        "\n",
        "So for instance, to make a plot of the angle of the major axis vs. time from the second calibration experiment of the third data set\n",
        "\n",
        "`plt.plot(calibrationdata[2].fits[1].nopulse.time, calibrationdata[2].fits[1].nopulse.theta`\n",
        "\n",
        "Or to make life easier on yourself typing\n",
        "```\n",
        "f = calibrationdata[2].fits[1]\n",
        "plt.plot(f.nopulse.time, f.nopulse.theta)\n",
        "```\n",
        "\n",
        "To make a histogram of the pulse phase for the 4th experiment in the 2nd data set\n",
        "```\n",
        "f = pulsedata[1].fits[3]\n",
        "plt.hist(f.pulse.phase)\n",
        "```\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "CN0c1fHbW4hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#examples from above\n",
        "\n",
        "#basic\n",
        "f = calibrationdata[2].fits[1]\n",
        "plt.plot(f.nopulse.time, f.nopulse.theta)\n",
        "plt.show()\n",
        "\n",
        "f = pulsedata[1].fits[3]\n",
        "plt.hist(f.pulse.phase)\n",
        "plt.show()\n",
        "\n",
        "#fancy\n",
        "f = calibrationdata[2].fits[1]\n",
        "plt.plot(f.nopulse.time-f.nopulse.time[0], np.rad2deg(f.nopulse.theta))\n",
        "plt.xlabel('elapsed time (s)')\n",
        "plt.ylabel('major axis angle (deg)')\n",
        "plt.show()\n",
        "\n",
        "f = pulsedata[1].fits[3]\n",
        "plt.hist(np.rad2deg(f.pulse.phase),weights = np.ones_like(f.pulse.phase)/f.pulse.phase.size)\n",
        "plt.xlabel('phase (deg)')\n",
        "plt.ylabel('fraction of pulses')\n",
        "plt.title(r'$\\phi$ = {:.1f} $\\pm$ {:.2f}'.format(np.mean(np.rad2deg(f.pulse.phase)), np.std(np.rad2deg(f.pulse.phase))))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "svvIwmCvXypE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now it's your turn\n",
        "\n",
        "Pick an experiment - let's say the 3rd fit from the 2nd calibration data set, but if this looks funky when you go to do your assignment, pick another one.\n",
        "\n",
        "In the example code, I'm using `f` as shorthand for `calibrationdata[1].fits[2]`, and you should too\n",
        "\n",
        "For this experiment, please \n",
        "1. Plot the minor axis vs. time. Remeber you will use the `nopulse` structure - the minor axis is stored in `f.nopulse.b`. Whether you make this plot basic or fancy is up to you\n",
        "1. Make a plot of the predicted and measured rotation rates vs. time \n",
        "  1. Calculate the predicted anharmonic precession rate: $\\Omega_{pred} = \\frac{3 \\pi}{4 T} \\frac{a b}{L^2}$ (or $\\frac{3}{8} \\omega \\frac{a b}{L^2}$ ) Hint: remember that the period is stored in `f.period` and the length is stored in `f.L`\n",
        "  1. Calculate the measured precession rate:  $\\Omega_{m} = \\frac{d\\theta}{d t}$. Hint: if `x` and `t` are numpy arrays, then `np.gradient(x,t)` = $\\frac{d x}{d t}$. Note the order of `x` and `t`\n",
        "  1. On the same (new) set of axes, plot the predicted precession rate $\\Omega_{pred} + \\Omega_{foucault}$ vs. time ($\\Omega_{foucault}$ = `omega_foucault`), and plot the measured precession rate vs. time. Convert everything to degrees per hr\n",
        "1. On a new set of axes, make a scatter plot of $\\Omega_m$ vs. $\\Omega_{pred} + \\Omega_{foucault}$, again in degrees/hr"
      ],
      "metadata": {
        "id": "WpEVfXmMa0Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here"
      ],
      "metadata": {
        "id": "2__i65FHaRHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ok, let's calibrate!\n",
        "\n",
        "I need you to write three functions\n",
        "\n",
        "`predictedPrecession_calibration(f)`, which will calculate the predicted rate of rotation at each time point for a given calibration experiment f\n",
        "\n",
        "`measuredPrecession_calibration(f)`, which will calculate $d\\theta/dt$ at each time point for a given calibration experiment f\n",
        "\n",
        "These just adapt what you did above. \n",
        "\n",
        "\n",
        "`lifetime_calibration(f)`, which will calculate the major axis lifetime (= twice the energy lifetime) for each calibration experiment.\n",
        "\n",
        "Here, please fit a line: $\\log(a) = -m(t-t0) + b$ and return the lifetime $\\tau = -1/m$ (hints `np.polyfit` and `np.log`)\n"
      ],
      "metadata": {
        "id": "cfIO0rZehq8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictedPrecession_calibration(f):\n",
        "  #calculates the predicted precession rate (in rad/s) for a calibration experiment\n",
        "  #input f = fit structure from a dataset\n",
        "  #output numpy array: 3/8 omega ab/L^2 + omega_foucault evaluated at each time point in f.nopulse.time\n",
        "  a = f.nopulse.a\n",
        "  b = f.nopulse.b\n",
        "  w = 2*np.pi/f.period\n",
        "  L = f.L\n",
        "  return #your calculation here\n",
        "\n",
        "def measuredPrecession_calibration(f):\n",
        "  #calculates the precession rate (in rad/s) of the major axis \n",
        "  #input f = fit structure from a dataset\n",
        "  #output numpy array: d theta/ dt\n",
        "  theta = f.nopulse.theta\n",
        "  t = f.nopulse.time\n",
        "  return #your calculation here\n",
        "\n",
        "def lifetime_calibration(f):\n",
        "  #calculates the amplitude (not energy or amplitude squared lifetime) in seconds for a calibration experiment\n",
        "  #input f = fit structure from a dataset\n",
        "  #output float = lifetime in seconds\n",
        "  a = f.nopulse.a\n",
        "  t = f.nopulse.time\n",
        "  #your code here\n",
        "  return #your code here\n",
        "  \n",
        "#test your code here - if you wrote the lifetime function correctly, you should see a scattered set of circles showing individual lifetime measurements for each setup\n",
        "#see next cell for an explanation of `applyFunctionToSet`\n",
        "lifetime, setup, _ = applyFunctionToSet(lifetime_calibration, calibrationdata)\n",
        "plt.scatter(setup[setup < 20], lifetime[setup < 20])\n",
        "plt.xlabel('setup number')\n",
        "plt.ylabel('amplitude lifetime')\n",
        "\n",
        "#test your code here - if you wrote the predicted and measured precession functions correctly, you should see a line relating predicted and measured rates\n",
        "pp = applyFunctionToSet(predictedPrecession_calibration, calibrationdata)[0]\n",
        "rp = applyFunctionToSet(measuredPrecession_calibration, calibrationdata)[0]\n",
        "\n",
        "plt.show()\n",
        "plt.plot(pp*deghr,rp*deghr, 'b.')\n",
        "p = np.polyfit(pp,rp,1)\n",
        "px = np.linspace(-300,300)\n",
        "plt.plot(px, p[0]*px + p[1])\n",
        "plt.xlabel('predicted precession rate (deg/hr)')\n",
        "plt.ylabel('measured precession rate (deg/hr)')\n",
        "plt.legend(('data','m = {:.2f}, b = {:.2f}'.format(p[0], deghr*p[1])))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8jzNWsSIhqiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question \n",
        "\n",
        "Does the measured precession rate match the predicted precession rate for the calibration data sets? \n",
        "\n",
        "*your answer here*\n",
        "\n",
        "If it doesn't that means there's something wrong with the data or your code. As of this writing, the data are OK (and plural!) so check your code."
      ],
      "metadata": {
        "id": "BSLRhsu5nSP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A new function for you to use\n",
        "\n",
        "```\n",
        "value, section, setup = applyFunctionToSet(fun, dataset)\n",
        "# for just value\n",
        "# value = applyFunctionToSet(fun, dataset)[0]\n",
        "# or\n",
        "# value,*_ = applyFunctionToSet(fun, dataset) \n",
        "```\n",
        "\n",
        "This function loops through all the data sets and runs `fun` on the fits from each one. It then gives you the output of that function concatenated together as one big array as the first return value\n",
        "\n",
        "It also returns two other arrays - section, which is the section number associated with each data point, and setup, which is the setup number associated with each data point\n",
        "\n",
        "So for instance, to find the lifetimes only from the Tuesday AM section (section 1), I would write\n",
        "\n",
        "```\n",
        "lifetime, setup, section = applyFunctionToSet(lifetime_calibration, calibrationdata)\n",
        "sectionOneLifetime = lifetime[section == 1]\n",
        "```\n",
        "\n",
        "If I only want the lifetimes but don't care about the section number, I would write\n",
        "```\n",
        "lifetime, *_ = applyFunctionToSet(lifetime_calibration, calibrationdata)\n",
        "```\n",
        "or\n",
        "```\n",
        "lifetime = applyFunctionToSet(lifetime_calibration, calibrationdata)[0]\n",
        "```\n",
        "\n",
        "For `dataset`, you can put in a list of datasets (e.g. `calibrationdata` or `pulsedata`) or you can use an individual data set (e.g. `calibrationdata[2]`)\n",
        "\n",
        "I used this function in the test code above - look at it and make sure  you understand how it works.\n"
      ],
      "metadata": {
        "id": "-O-EuxUXnL8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate the amplitude lifetime for each setup\n",
        "For now we'll ignore the section data, but we can look at if things are bonkers\n",
        "\n",
        "1. Calculate the lifetime and setup number for each fit in the `calibrationdata` set using `applyFunctionToSet` and `lifetime_calibration`. Hint: I've pretty much told you exactly how to do this above. If you don't want to store the setup number, it's conventional to replace the variable name with `_`\n",
        "\n",
        "1. Call the number of setups nsetups. Let's define `nsetups = 200` - it doesn't matter as long as it's bigger than the actual number of setups, and since we used `setupNumber = 99` to indicate you didn't enter one, it needs to be bigger than this. Create a numpy array called `median_lifetime` of length `nsetups` filled with `np.nan`. Hint: you can use `np.full` or a `for` loop\n",
        "\n",
        "1. Using a for loop iterating over a reasonable number of setups `for i in range(20):`, \n",
        "  1. check to see if you have any lifetime data matching that setup (`np.any()` is your friend here). \n",
        "  1. If you have any lifetime data for that setup, calculate the **median** (`np.median`) of all lifetimes for that setup and store the result in `median_lifetime[i]` Hint: logical indexing is your friend here. Remember logical indexing looks like `y[x == i]` \n",
        "  1. print the setup number and the median so you can see if it looks reasonable\n",
        "\n",
        "1. Calculate the median of all lifetimes\n",
        "\n",
        "\n",
        "1. Set any value of `median_lifetime` that is nan (use np.isnan) to the median of all lifetimes. This means that if we don't have any calibration data for that setup, just use the calibration data for all setups\n",
        "\n",
        "\n",
        "1. Iterate over all fits in the pulse data set and add a field `lifetime` equal to the median lifetime for that fit (`f.lifetime = median_lifetime[f.setupNumber]`). You can do this with a set of nested for loops.\n",
        "\n",
        "```\n",
        "for d in pulsedata: \n",
        "  for f in d.fits:\n",
        "    ...\n",
        "```"
      ],
      "metadata": {
        "id": "_smB_iZvpqfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsetups = 200\n",
        "\n",
        "#your code here\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AtZN5F02tWEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's figure out the rotation induced by the pulse\n",
        "\n",
        "We need 4 more functions\n",
        "\n",
        "1. `anharmonicAndFoucaultRotation_pulse(f)` - calculates the amount you expect the orbit to rotate between pulses (this is an angle - rate * time, not a rate) =\n",
        "$(\\frac{3}{8}\\omega \\frac{a b}{L^2} + \\Omega_{foucault})\\Delta t$\n",
        "\n",
        "1. `measuredRotation_pulse(f)` - just calculates the difference between $\\theta$ at subsequent times - compute using `np.gradient(..)` with just one argument - aw heck, I'll just write this for you it's so easy\n",
        "\n",
        "1. `rotationPrefactor` - this is the thing that multiplies cot($2 \\phi$) (or whatever you pick from Schumacher and Tarbet) = $\\frac{-2 b \\Delta a}{a^2-b^2}$\n",
        "\n",
        "The only tricky bit is that you need to include the effects of amplitude decay (the coil is pushing harder than you think if you just look at the change in amplitude)\n",
        "\n",
        "$\\Delta a = $grad$(a) + a * $grad$(t)/\\tau$ where grad is computed using `np.gradient` and no arguments. The first term is how much a is changed by the pulse, the second term is how much a would have decreased if the coil didn't turn on. Together they measure the effect of the coil \n",
        "\n",
        "1. `pulsePhase(f)` - literally just return the list of pulse phases so we can get them all using applyFunctionToSet. You don't really need this function; you could just use a `lambda` expression. Heck, I'll write this one for you too"
      ],
      "metadata": {
        "id": "4kyxv_rmzaTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def anharmonicAndFoucaultRotation_pulse(f):\n",
        "  a = f.pulse.a\n",
        "  b = f.pulse.b\n",
        "  L = f.L\n",
        "  w = 2*np.pi/f.period\n",
        "  t = f.pulse.time\n",
        "  rate = #your code here\n",
        "  dt = #your code here\n",
        "  return rate*dt\n",
        "\n",
        "def measuredRotation_pulse(f):\n",
        "  return np.gradient(f.pulse.theta)\n",
        "\n",
        "def rotationPrefactor(f):\n",
        "  lifetime = f.lifetime\n",
        "  a = f.pulse.a\n",
        "  b = f.pulse.b\n",
        "  L = f.L\n",
        "  w = 2*np.pi/f.period\n",
        "  t = f.pulse.time\n",
        "\n",
        "  #your code here\n",
        "  return #your code here\n",
        "\n",
        "def pulsePhase(f):\n",
        "  return f.pulse.phase"
      ],
      "metadata": {
        "id": "rdBdN6zrS-gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we find out the answer!\n",
        "\n",
        "Here you'll use one other function I've written (introduced in earlier labs)\n",
        "```\n",
        "(m,m_e) = fitLineThroughZero(x,y)\n",
        "```\n",
        "finds the best fit to $y = mx$ (calculated as $m =\\frac{\\sum_i x_i y_i}{\\sum x_i^2}$) `m_e` is the error in the fit estimate, *assuming all the measurements are independent,* which isn't true -- a correction is incorporated below\n",
        "\n",
        "1. gather together the measured rotation, predicted (aharmonic and foucault only) rotation, rotation prefactor, and phase for all the pulses in all the experiments. For example \n",
        "```\n",
        "measured_rotation = applyFunctionToSet(measuredRotation_pulse, pulsedata)[0] \n",
        "```\n",
        "\n",
        "1. calculate the `residual_rotation` as measured rotation - predicted rotation\n",
        "\n",
        "1. We want to group all pulses with similar phases together for analysis. For instance we might want to look at all pulses within +/- 2 phase degrees of a central value. We also want to define a range of interest, so we don't end up looking at messed up / error pulses. I've written this for you, but I want you to understand it\n",
        "  1. Define `minphase = 20` and `maxphase = 75`. These end up being potentially approximate (up to `phasebin` off)\n",
        "  1. Define `phasebin` = 4\n",
        "  1. `nbins` is the number of bins (to initialize the arrays)\n",
        "  1. `idx` is the bin index, which indicates which phases get grouped together. `floor_divide(x,y)` is the largest integer $n$ s.t. $n y  <= x$  (divide and round down)\n",
        "  1. bin0 is the starting bin - the bin that contains `minphase`\n",
        "  1. Initialize arrays for use laster\n",
        "    1. binhasdata - whether there are any pulses in a particular bin\n",
        "    1. meanphase - the average phase of pulses in that bin\n",
        "    1. slope - the relation between residual rotation and the rotation prefactor\n",
        "    1. slope_eb - the uncertainty in that estimate\n",
        "\n",
        "1. run a for loop over the valid bin values `for i in range(bin0,nbins):`\n",
        "  1. `binhasdata[i]` is true if any values of idx == i \n",
        "  1. if `binhasdata[i]` then continue analysis\n",
        "    1. `meanphase[i]` is the mean (`np.mean`) of all phases for which idx == i (hint logical indexing, this whole thing is all logical indexing)\n",
        "    1. use `(m,m_e) = fitLineThroughZero` to find a relation between of the form `residual_rotation` = m`*rotation_prefactor` **only for those points where idx == i** (ie only for pulses within the phase bin)\n",
        "    1. assign 'm' to 'slope[i]'\n",
        "    1. the calculation of the error assumes that each data point is independent. But in fact, these points all come from the same smooth curve. So you need to multiply by the square root of the number of pulses you think constitute one independent measurement. As a ballpark, I'm guessing 100 pulses, so use a factor of 10, but this is clearly a guesstimate. So assign `10*m_e` to `slope_eb`\n",
        "    1. I've defined a quantity `doplot = True` This lets you turn off the plotting, if you want later. So in a block beginning `if doplot:`\n",
        "      1. For only values where idx == i, plot the residual rotation (y axis) vs. the rotation prefactor (x axis) with black dots\n",
        "      1. Add a magenta line showing the best fit line you calculated above\n",
        "      1. Title the plot \"phi = (mean phase), slope = (m), cot(2phi) = (1/tan(2phi))\" where obviously the parts in () should contain calculated numbers\n",
        "\n",
        "1. After the for loop, keep only the values that have data. e.g. `meanphase = meanphase[binhasdata]` (repeat for slope and slope_eb)\n",
        "\n"
      ],
      "metadata": {
        "id": "IefBeKdv4uQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "measured_rotation = #your code here\n",
        "predicted_rotation = #your code here\n",
        "rotation_prefactor = #your code here\n",
        "residual_rotation = #your code here\n",
        "phase = #your code here\n",
        "\n",
        "#my code to tod the setup in step 3\n",
        "minphase = 20\n",
        "maxphase = 75\n",
        "phasebin = 4 #degrees\n",
        "nbins = np.round(maxphase/phasebin).astype(int) #last bin has at least 1/2 phasebin before maxphase or it's excluded\n",
        "idx = np.floor_divide(np.rad2deg(phase), phasebin).astype(int)\n",
        "bin0 = np.floor_divide(minphase,phasebin)\n",
        "\n",
        "binhasdata = np.full((nbins,), 0, dtype = bool)\n",
        "meanphase = np.full((nbins,), np.nan)\n",
        "slope = np.full((nbins,), np.nan)\n",
        "slope_eb = np.full((nbins,), np.nan)\n",
        "doplot = True\n",
        "\n",
        "for i in range(bin0,nbins):\n",
        "  #your code here\n",
        "\n",
        "#your code here"
      ],
      "metadata": {
        "id": "AoGzw9E5PfuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What you've done all the work for\n",
        "\n",
        "1. Make an error bar plot of the meanphase(convert to degrees) (x) slope (y) and slope_eb, with 'o' markers\n",
        "1. Overlay with the predictions of our model $1/\\tan(2\\phi)$ and of Schumacher and Tarbet (do both $0.5(\\pi/2 - \\phi)/\\tan(\\phi)$ and $0.5(\\pi/2 - \\phi)/\\sin(\\phi)$\n",
        "1. When I looked at the Schumacher paper, I'm pretty sure it should be $0.5(\\pi/2 - \\phi)/\\tan(\\phi)$, but in my notes I have $0.25(\\pi/2 - \\phi)/\\tan(\\phi)$. Plot that one too\n"
      ],
      "metadata": {
        "id": "Tgo05sbc-kgb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn-p9FDnyOrA"
      },
      "source": [
        "#Questions\n",
        "\n",
        "Do the data support (or disprove) the following statements (explain)?\n",
        "\n",
        "1. Applying the drive force rotates the orbit by an amount proportional to $\\frac{2b \\Delta a}{a^2 - b^2}$\n",
        "1. Applying the drive force rotates the orbit by an amount proportional to $ \\cot(2\\phi)$\n",
        "1. Applying the drive force rotates the orbit by an amount proportional to $(\\pi/2 - \\phi)/\\tan(\\phi)$ or $(\\pi/2 - \\phi)/\\sin(\\phi)$\n",
        "\n",
        "If the answer to 2 was yes and 3 was no, expain what the key differentating feature of the data is. \n",
        "\n",
        "Does the data support our final model $\\Delta \\theta = -\\frac{2b \\Delta a}{a^2 - b^2} \\cot(2 \\phi)$\n"
      ]
    }
  ]
}